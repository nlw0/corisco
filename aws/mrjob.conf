runners:
  emr:
    aws_access_key_id: xxx
    # We run on in the west region because we're located on the west coast,
    # and there are no eventual consistency issues with newly created S3 keys.
    aws_region: sa-east-1
    aws_secret_access_key: xxx
    # alternate tmp dir
    base_tmp_dir: /home/nwerneck/corisco/aws/scratch/$USER
    # # $BT is the path to our source tree. This lets us add modules to
    # # install on EMR by simply dumping them in this dir.
    bootstrap_files:
    - /home/nwerneck/corisco/aws/mypackages/corisco-0.1dev.tar.gz
    - /home/nwerneck/corisco/aws/mypackages/filtersqp-0.1dev.tar.gz
    bootstrap_cmds:
    # - sudo apt-get install -y python-imaging python-numpy python-scipy python-pip cython
    - sudo apt-get install -y python-imaging python-pip
    - sudo pip install numpy scipy cython
    # - sudo easy_install pip
    # - sudo pip install filtersqp-0.1dev.tar.gz corisco-0.1dev.tar.gz
    # - sudo easy_install cython
    - tar xfz filtersqp-0.1dev.tar.gz; cd filtersqp-0.1dev; sudo python setup.py install;
    - tar xfz corisco-0.1dev.tar.gz; cd corisco-0.1dev; cython corisco/corisco_aux.pyx; python setup.py build_ext --inplace; sudo python setup.py install;

    # specifying an ssh key pair allows us to ssh tunnel to the job tracker
    # and fetch logs via ssh
    ec2_key_pair: kvelertak
    ec2_key_pair_file: /home/nwerneck/id_rsa.pub
    # use beefier instances in production
    #ec2_instance_type: m1.medium
    ec2_instance_type: c1.xlarge
    # but only use one unless overridden
    num_ec2_instances: 1
    # use our local time zone (this is important for deciding when
    # days start and end, for instance)
    cmdenv:
      TZ: America/Sao_Paulo
    # # we create the src-tree.tar.gz tarball with a Makefile. It only contains
    # # a subset of our code
    # python_archives: &python_archives
    # - $BT/aws/src-tree.tar.gz
    # our bucket also lives in the us-west region
    s3_log_uri: s3://corisco/tmp/logs/
    s3_scratch_uri: s3://corisco/tmp/
    # setup_cmds: &setup_cmds
    # # these files are different between dev and production, so they're
    # # uploaded separately. copying them into place isn't safe because
    # # src-tree.tar.gz is actually shared between several mappers/reducers.
    # # Another safe approach would be to add a rule to Makefile.emr that
    # # copies these files if they haven't already been copied (setup_cmds
    # # from two mappers/reducers won't run simultaneously on the same machine)
    # - ln -sf $(readlink -f config.py) src-tree.tar.gz/config/config.py
    # - ln -sf $(readlink -f secret.py) src-tree.tar.gz/config/secret.py
    # # run Makefile.emr to compile C code (EMR has a different architecture,
    # # so we can't just upload the .so files)
    # - cd src-tree.tar.gz; make -f Makefile.emr
    # generally, we run jobs on a Linux server separate from our desktop
    # machine. So the SSH tunnel needs to be open so a browser on our
    # desktop machine can connect to it.
    ssh_tunnel_is_open: true
    ssh_tunnel_to_job_tracker: true
    # # upload these particular files on the fly because they're different
    # # between development and production
    # upload_files: &upload_files
    # - $BT/config/config.py
    # - $BT/config/secret.py
